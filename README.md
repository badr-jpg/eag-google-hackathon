# Readme

So far, this just has the code that calls the PaLM bison model. We can build around this for anything txt2txt related


## Instructions


## Getting started with Vertex AI Generative AI

## Before you begin

This is a simple starter boilerplate that gives you a basic FastAPI setup with a few endpoints. It is meant to be used as a starting point for your own projects.

### Clone and install dependencies

In your terminal, run the following commands:
```
cd Google-VertexAI-FastAPI
cd app
pip install -r requirements.txt
```

### Start the server and test

Once you have installed the dependencies, you can start the server by running: `uvicorn main:app --reload --port 8080` in the `app` directory.
When the server is running, you can test it by going to `http://localhost:8080/docs` in your browser. You should see the Swagger UI where you can test the endpoints.

![image](https://github.com/lablab-ai/Google-VertexAI-FastAPI/assets/2171273/13df1172-0b77-43f3-85a0-0bf936bbd8db)
![image](https://github.com/lablab-ai/Google-VertexAI-FastAPI/assets/2171273/e69f7892-6945-4d85-987e-dbbc23e553bd)

Good luck! and don't forget to star this repo if you like it!

**Thank you** for reading! If you enjoyed this tutorial you can find more and continue reading
[on our tutorial page](https://lablab.ai/t/)

---
